{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AN2EAUu9JBwF"
      },
      "outputs": [],
      "source": [
        "!pip install beautifulsoup4\n",
        "!pip install google\n",
        "!pip install newspaper3k"
      ],
      "id": "AN2EAUu9JBwF"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w-ULku7ZJBwI"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from difflib import SequenceMatcher\n",
        "import newspaper\n",
        "from newspaper import Config\n",
        "from newspaper import Article\n",
        "import numpy as np\n",
        "from os.path import exists\n",
        "import pandas as pd"
      ],
      "id": "w-ULku7ZJBwI"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KshLQ2mLJBwJ"
      },
      "outputs": [],
      "source": [
        "def removeLine(x):\n",
        "    if x[0] =='|':\n",
        "        return x[1:].strip()\n",
        "    else:\n",
        "        return x"
      ],
      "id": "KshLQ2mLJBwJ"
    },
    {
      "cell_type": "code",
      "source": [
        "def similar(a, b): \n",
        "    return SequenceMatcher(None, a, b).ratio()"
      ],
      "metadata": {
        "id": "LAQG1QZuChH_"
      },
      "id": "LAQG1QZuChH_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3xvP9aJoJBwK"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data/scraped_posts/scraped_reddit_posts.csv\", usecols = ['url','title'])\n",
        "list_of_urls= df['url'].values.tolist()\n",
        "list_of_titles= df['title'].values.tolist()"
      ],
      "id": "3xvP9aJoJBwK"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mBny546tJBwK"
      },
      "outputs": [],
      "source": [
        "df2 = df[df['url'].str.contains(\"web.archive.org|https://archive.\")] "
      ],
      "id": "mBny546tJBwK"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D33rIQwuJBwK"
      },
      "outputs": [],
      "source": [
        "df3 = df2[df2['title'].str.contains(\"|\")]"
      ],
      "id": "D33rIQwuJBwK"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "M1r6tb6WJBwL"
      },
      "outputs": [],
      "source": [
        "df3[['teaser', 'answer']] = df3['title'].str.split('|',n=1, expand=True)"
      ],
      "id": "M1r6tb6WJBwL"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "MS-uAHWcJBwM"
      },
      "outputs": [],
      "source": [
        "USER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0'\n",
        "\n",
        "config = Config()\n",
        "config.browser_user_agent = USER_AGENT\n",
        "config.request_timeout = 10"
      ],
      "id": "MS-uAHWcJBwM"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "gTMyhoDaJBwM",
        "outputId": "85c9a7f1-7fd9-44cb-cde0-9a8c12ab292a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4 title did not match\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11 title did not match\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24 title did not match\n",
            "25\n",
            "26 title did not match\n",
            "27\n",
            "28 title did not match\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35 title did not match\n",
            "36\n",
            "37\n",
            "38 title did not match\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63 title did not match\n",
            "64\n",
            "65 error\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72 title did not match\n",
            "73\n",
            "74 title did not match\n",
            "75 title did not match\n",
            "76 title did not match\n",
            "77 title did not match\n",
            "78\n",
            "79\n",
            "80 title did not match\n",
            "81\n",
            "82\n",
            "83\n",
            "84 title did not match\n",
            "85 title did not match\n",
            "86 title did not match\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91 title did not match\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96 title did not match\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101 error\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108 title did not match\n",
            "109\n",
            "110\n",
            "111\n",
            "112 title did not match\n",
            "113 title did not match\n",
            "114\n",
            "115 error\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n"
          ]
        }
      ],
      "source": [
        "list_of_urls= df3['url'].values.tolist()\n",
        "list_of_teasers= df3['teaser'].values.tolist()\n",
        "\n",
        "# modified from https://stackoverflow.com/questions/69711582/newspaper3k-export-to-csv-on-first-row-only\n",
        "index=0\n",
        "list_of_texts = []\n",
        "for url in list_of_urls:\n",
        "    # web.archive links work, but archive.fo or archive.is have time-out/captcha error\n",
        "    # we can google the actual web page from the teaser title\n",
        "    # replace archive links with first link in google search of teaser\n",
        "    if 'https://archive.' in list_of_urls[index]:\n",
        "        query = list_of_teasers[index]\n",
        "        try:\n",
        "            for j in search(query, tld=\"co.in\", num=1, stop=1, pause=0):\n",
        "                url = j\n",
        "        except:\n",
        "            pass #it appears there could be time out errors, can increase timeout\n",
        "    try:\n",
        "        article = newspaper.Article(url,config=config)\n",
        "        article.download()\n",
        "        article.parse()\n",
        "        article_meta_data = article.meta_data\n",
        "        text = article.text\n",
        "        title = article.title\n",
        "        # check that article title of webpage is at least 50% similar to the teaser\n",
        "        # if not, it is probably the wrong article\n",
        "        if similar(title,list_of_teasers[index]) < 0.5:\n",
        "            text = None\n",
        "            print(index, 'title did not match')\n",
        "        else:\n",
        "            print(index)\n",
        "    except:\n",
        "        text = None \n",
        "        print(index,'error')\n",
        "    index+=1\n",
        "    #Write to file [url, article text]\n",
        "    list_of_texts.append(text)"
      ],
      "id": "gTMyhoDaJBwM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3aneLyHJBwO"
      },
      "outputs": [],
      "source": [
        "df3['article']= list_of_texts"
      ],
      "id": "s3aneLyHJBwO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMGA7USIJBwP"
      },
      "outputs": [],
      "source": [
        "df3['teaser'] = df3['teaser'].apply(lambda x: x.strip())\n"
      ],
      "id": "SMGA7USIJBwP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta2049GZJBwP"
      },
      "outputs": [],
      "source": [
        "df3 = df3[df3['title'].str.contains(\"\\|\")]"
      ],
      "id": "ta2049GZJBwP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eb0iaW80JBwQ",
        "outputId": "e64f89c1-f3e2-4bc7-d2d3-c645c9b707df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/6v/7l4sg8g92sj0mn3b96s3bd740000gn/T/ipykernel_16976/3641060672.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df3['answer'] = df3['answer'].apply(lambda x: x.strip())\n"
          ]
        }
      ],
      "source": [
        "df3['answer'] = df3['answer'].apply(lambda x: x.strip())"
      ],
      "id": "eb0iaW80JBwQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAve47IlJBwR"
      },
      "outputs": [],
      "source": [
        "df3 = df3.drop_duplicates(subset=['title'])"
      ],
      "id": "hAve47IlJBwR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmKIb7WHJBwR"
      },
      "outputs": [],
      "source": [
        "df3 = df3[df3['article']!='']"
      ],
      "id": "YmKIb7WHJBwR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ksBFiscJBwR"
      },
      "outputs": [],
      "source": [
        "df3 = df3[df3['answer']!='']"
      ],
      "id": "7ksBFiscJBwR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60nMT8ZzJBwS"
      },
      "outputs": [],
      "source": [
        "df3['answer'] = df3['answer'].apply(removeLine)"
      ],
      "id": "60nMT8ZzJBwS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFffZGEtJBwS"
      },
      "outputs": [],
      "source": [
        "df3.to_pickle('data_full_pandas.pkl')\n"
      ],
      "id": "MFffZGEtJBwS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPhujAhZJBwS"
      },
      "outputs": [],
      "source": [
        "dnp = df3.to_numpy()\n",
        "np.save('data_full_numpy.npy', dnp)"
      ],
      "id": "GPhujAhZJBwS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpVIoVfeJBwS"
      },
      "outputs": [],
      "source": [
        "df4 = df3[df3['title'].str.contains(\"\\|\")]"
      ],
      "id": "XpVIoVfeJBwS"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "clean_data_and_get_articles.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}